# # -*- coding: utf-8 -*-
# """Liver_Tumor_Detection_model.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1pEuC_Z_-IjnpxmOiCEMxURqIPK_UAea_
# """

# !pip install roboflow

# from roboflow import Roboflow
# rf = Roboflow(api_key="API_KEY")
# project = rf.workspace("liver-tumor").project("liver-tumor-detection")
# version = project.version(2)
# dataset = version.download("yolov8")

# import os

# # folder path
# dir_path = r'/content/Liver-Tumor-Detection-2/train/images'
# count = 0
# # Iterate directory
# for path in os.listdir(dir_path):
#     # check if current path is a file
#     if os.path.isfile(os.path.join(dir_path, path)):
#         count += 1
# print('File count:', count)

# pip install pyyaml

# import yaml

# # Specify the path to your .yaml file
# file_path = "/content/Liver-Tumor-Detection-2/data.yaml"

# # Open and load the .yaml file
# with open(file_path, 'r') as file:
#     data = yaml.safe_load(file)

# # Print the contents of the file
# print(data)

# import yaml

# # Paths to dataset folders
# dataset_paths = {
#     'train': '/content/Liver-Tumor-Detection-2/train',
#     'val': '/content/Liver-Tumor-Detection-2/valid',
#     'test': '/content/Liver-Tumor-Detection-2/test',
#     'nc': 1,  # Number of classes
#     'names': ['tumor']  # Class names
# }

# # Save the YAML file
# with open('liver_tumor.yaml', 'w') as file:
#     yaml.dump(dataset_paths, file)

# print("liver_tumor.yaml created successfully!")

# !pip install ultralytics
# !pip install opencv-python

from ultralytics import YOLO

# Paths to your dataset and model
data_yaml = "/content/liver_tumor.yaml"  # Create this YAML file to define your dataset
model_save_path = "runs/detect/yolov11_liver_tumor"

# 1. Load the YOLOv11 model
model = YOLO("yolov8n.pt")  # Using YOLOv8 as YOLOv11 is currently based on Ultralytics core

# 2. Train the model
model.train(
    data=data_yaml,  # Path to the dataset YAML
    epochs=75,       # Number of epochs
    imgsz=640,       # Image size
    batch=16,        # Batch size
    name="liver_tumor_model.pt"  # Save results under this name
)

# 3. Evaluate the model
results = model.val()

import cv2
import matplotlib.pyplot as plt
from ultralytics import YOLO
import os

def plot_ground_truth(image_path, label_path):
    """
    Plots the ground-truth bounding boxes from the label file on the given image.
    """
    # Load the image
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Read label file and draw boxes
    with open(label_path, "r") as file:
        for line in file:
            data = line.strip().split()
            cls, cx, cy, w, h = map(float, data)

            # Convert normalized coordinates (cx, cy, w, h) to pixel coordinates
            height, width, _ = img.shape
            x1 = int((cx - w / 2) * width)
            y1 = int((cy - h / 2) * height)
            x2 = int((cx + w / 2) * width)
            y2 = int((cy + h / 2) * height)

            # Draw the bounding box (green for ground-truth)
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img, "tumor (GT)", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Display the image with bounding boxes
    plt.figure(figsize=(10, 10))
    plt.imshow(img)
    plt.axis("off")
    plt.title("Ground Truth")
    plt.show()

    return img


def test_model(image_path, model_path="/content/liver_tumor_segmentation_model.pt"):
    """
    Uses the trained YOLOv8 model to predict bounding boxes on the given image.
    """
    # Load the trained model
    model = YOLO(model_path)

    # Run inference on the image
    results = model.predict(source=image_path, save=True)

    # Check if image0.jpg is created
    result_img_path = "/content/runs/detect/predict4/image-0033_jpg.rf.72c970c29fbe513a8c51b5b7012d0dec.jpg"
    if not os.path.exists(result_img_path):
        print(f"Error: {result_img_path} does not exist.")
        return

    # Visualize predictions
    results_img = cv2.imread(result_img_path)
    if results_img is None:
        print(f"Error: Failed to read {result_img_path}.")
        return

    results_img = cv2.cvtColor(results_img, cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(10, 10))
    plt.imshow(results_img)
    plt.axis("off")
    plt.title("Predictions")
    plt.show()



# Paths to image and label file
image_path = "/content/Liver-Tumor-Detection-2/valid/images/image-0033_jpg.rf.72c970c29fbe513a8c51b5b7012d0dec.jpg"  # Replace with the image path
label_path = "/content/Liver-Tumor-Detection-2/valid/labels/image-0033_jpg.rf.72c970c29fbe513a8c51b5b7012d0dec.txt"  # Replace with the corresponding label file path

# 1. Plot Ground Truth
gt_img = plot_ground_truth(image_path, label_path)

# 2. Test the Model
test_model(image_path)

import cv2
import matplotlib.pyplot as plt
from ultralytics import YOLO

def test_model(image_path, model_path="/content/runs/detect/liver_tumor_model.pt/weights/best.pt"):
    """
    Uses the trained YOLOv8 model to predict bounding boxes on the given image.
    The output image is saved as 'output1.jpg' with bounding boxes drawn.
    """
    # Load the trained model
    model = YOLO(model_path)

    # Run inference on the image
    results = model.predict(source=image_path, save=False)  # Do not save in 'runs/detect/'

    # Extract bounding boxes, labels, and confidences
    boxes = results[0].boxes.xyxy  # Get the bounding box coordinates
    labels = results[0].boxes.cls  # Get the class labels
    confidences = results[0].boxes.conf  # Get the confidence scores

    # Load the image
    img = cv2.imread(image_path)

    # Loop through the results and draw the bounding boxes on the image
    for i in range(len(boxes)):
        x1, y1, x2, y2 = map(int, boxes[i])  # Convert box coordinates to integers
        label = int(labels[i])  # Convert label to integer
        confidence = confidences[i]  # Confidence score

        # Draw the bounding box (Blue for bounding box, Red for the label)
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red rectangle
        text = f"Class {label} ({confidence:.2f})"
        cv2.putText(img, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

    # Save the image with bounding boxes as 'output1.jpg'
    output_path = "output1.jpg"
    cv2.imwrite(output_path, img)

    # Visualize predictions
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(10, 10))
    plt.imshow(img_rgb)
    plt.axis("off")
    plt.title("Predictions")
    plt.show()

    print(f"Output image saved as {output_path}")


# Example usage
image_path = "/content/Liver-Tumor-Detection-2/valid/images/image-0006_jpg.rf.f900f8e4bd04cb89b5966b6d5e3304b3.jpg"  # Replace with your image path

# Test the Model and save the result as output1.jpg
test_model(image_path)

import cv2
import matplotlib.pyplot as plt
from ultralytics import YOLO

def test_model(image_path, model_path="/content/runs/detect/liver_tumor_model.pt/weights/best.pt"):
    """
    Enhances the YOLO model predictions by calculating tumor size, location, severity, and count.
    """
    # Load the trained model
    model = YOLO(model_path)

    # Run inference on the image
    results = model.predict(source=image_path, save=False)  # Do not save in 'runs/detect/'

    # Extract bounding boxes, labels, and confidences
    boxes = results[0].boxes.xyxy  # Bounding box coordinates
    labels = results[0].boxes.cls  # Class labels
    confidences = results[0].boxes.conf  # Confidence scores

    # Load the image
    img = cv2.imread(image_path)

    # Tumor details
    tumor_details = []

    # Loop through results and process each bounding box
    for i in range(len(boxes)):
        x1, y1, x2, y2 = map(int, boxes[i])  # Convert box coordinates to integers
        label = int(labels[i])  # Convert label to integer
        confidence = confidences[i]  # Confidence score

        if confidence < 0.5:
          continue

        # label name
        if label == 0:
            label = "tumor"

        # Calculate size (area) of the tumor
        width = (x2 - x1) * 0.2645833333
        height = (y2 - y1) * 0.2645833333
        area = width * height

        # Determine severity based on tumor size
        if area < 1000:
            severity = "Low"
        elif 1000 <= area < 5000:
            severity = "Moderate"
        else:
            severity = "High"

        # Determine tumor location (e.g., divide liver into quadrants)
        center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2
        if center_x < img.shape[1] // 2 and center_y < img.shape[0] // 2:
            location = "Upper Left lobe"
        elif center_x >= img.shape[1] // 2 and center_y < img.shape[0] // 2:
            location = "Upper Right lobe"
        elif center_x < img.shape[1] // 2 and center_y >= img.shape[0] // 2:
            location = "Lower Left lobe"
        else:
            location = "Lower Right lobe"

        # Append details
        tumor_details.append({
            "label": label,
            "confidence": round(float(confidence), 2),
            "area": area,
            "size": f"{width}mm x {height}mm",
            "location": location,
            "severity": severity
        })

        # Draw the bounding box
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)
        text = f"Class {label}, {severity} ({confidence:.2f})"
        cv2.putText(img, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

    # Save the image with bounding boxes as 'output1.jpg'
    output_path = "output1.jpg"
    cv2.imwrite(output_path, img)

    # Visualize predictions
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(10, 10))
    plt.imshow(img_rgb)
    plt.axis("off")
    plt.title("Predictions")
    plt.show()

    print(f"Output image saved as {output_path}")
    print("\nTumor Details:")
    for i, tumor in enumerate(tumor_details, 1):
        print(f"Tumor {i}: {tumor}")

# Example usage
image_path = "/content/Liver-Tumor-Detection-2/valid/images/image-0033_jpg.rf.72c970c29fbe513a8c51b5b7012d0dec.jpg"  # Replace with your image path

# Test the model and save the result as output1.jpg
test_model(image_path)

import cv2
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO

def carve_tumor_edges(image, x1, y1, x2, y2):
    """
    Carves out the exact edges of the tumor within the bounding box.
    """
    # Crop the ROI from the bounding box
    roi = image[y1:y2, x1:x2]

    # Convert to grayscale
    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian blur to reduce noise
    blurred_roi = cv2.GaussianBlur(gray_roi, (5, 5), 0)

    # Apply Canny edge detection
    edges = cv2.Canny(blurred_roi, 50, 150)

    # Find contours
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Draw contours on the ROI for visualization
    contour_img = cv2.cvtColor(gray_roi, cv2.COLOR_GRAY2BGR)
    cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 2)

    # Calculate tumor shape metrics
    tumor_area = 0
    tumor_perimeter = 0
    shape = "Unknown"
    if contours:
        largest_contour = max(contours, key=cv2.contourArea)
        tumor_area = cv2.contourArea(largest_contour)
        tumor_perimeter = cv2.arcLength(largest_contour, True)

        # Calculate shape characteristics
        x, y, w, h = cv2.boundingRect(largest_contour)
        aspect_ratio = float(w) / h
        circularity = 4 * np.pi * (tumor_area / (tumor_perimeter ** 2))

        if circularity > 0.8:
            shape = "circular"
        elif aspect_ratio > 1.2:
            shape = "elongated (horizontal)"
        elif aspect_ratio < 0.8:
            shape = "elongated (vertical)"
        else:
            shape = "irregular"

    # Display the edges and contours
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(edges, cmap='gray')
    plt.title("Edges")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(contour_img)
    plt.title("Contours")
    plt.axis("off")
    plt.show()

    return tumor_area, tumor_perimeter, shape


def test_model(image_path, model_path="/content/liver_tumor_segmentation_model.pt"):
    """
    Enhances the YOLO model predictions by calculating tumor size, location, shape, severity, and count.
    """
    # Load the trained model
    model = YOLO(model_path)

    # Run inference on the image
    results = model.predict(source=image_path, save=False)

    # Load the image
    img = cv2.imread(image_path)

    # Tumor details
    tumor_details = []

    # Loop through results and process each bounding box
    for detection in results[0].boxes.data:  # Each detection
        # Extract bounding box coordinates and details
        x1, y1, x2, y2 = map(int, detection[:4])  # Bounding box coordinates
        confidence = float(detection[4])  # Confidence score
        label = int(detection[5])  # Class label

        if confidence < 0.5:
            continue

        # Tumor label
        tumor_label = "tumor"

        # Calculate size (area) of the tumor
        width = (x2 - x1) * 0.2645833333
        height = (y2 - y1) * 0.2645833333
        area = width * height

        # Get tumor shape and metrics
        tumor_area, tumor_perimeter, shape = carve_tumor_edges(img, x1, y1, x2, y2)

        # Determine severity based on tumor size
        if area < 1000:
            severity = "Low"
        elif 1000 <= area < 5000:
            severity = "Moderate"
        else:
            severity = "High"

        # Determine tumor location (e.g., divide liver into quadrants)
        center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2
        if center_x < img.shape[1] // 2 and center_y < img.shape[0] // 2:
            location = "Upper Left lobe"
        elif center_x >= img.shape[1] // 2 and center_y < img.shape[0] // 2:
            location = "Upper Right lobe"
        elif center_x < img.shape[1] // 2 and center_y >= img.shape[0] // 2:
            location = "Lower Left lobe"
        else:
            location = "Lower Right lobe"

        # Append details
        tumor_details.append({
            "label": tumor_label,
            "confidence": round(confidence, 2),
            "area": round(area, 2),
            "size": f"{width:.2f}mm x {height:.2f}mm",
            "location": location,
            "severity": severity,
            "shape": shape,
            "tumor_area": round(tumor_area, 2),
            "tumor_perimeter": round(tumor_perimeter, 2)
        })

        # Draw the bounding box
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        text = f"{tumor_label}, {severity} ({confidence:.2f})"
        cv2.putText(img, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Save the image with bounding boxes as 'output.jpg'
    output_path = "output.jpg"
    cv2.imwrite(output_path, img)

    # Visualize predictions
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(10, 10))
    plt.imshow(img_rgb)
    plt.axis("off")
    plt.title("Predictions")
    plt.show()

    print(f"Output image saved as {output_path}")
    print("\nTumor Details:")
    for i, tumor in enumerate(tumor_details, 1):
        print(f"Tumor {i}: {tumor}")


# Example usage
image_path = "/content/Liver-Tumor-Detection-2/valid/images/image-0033_jpg.rf.72c970c29fbe513a8c51b5b7012d0dec.jpg"
test_model(image_path)

