# # -*- coding: utf-8 -*-
# """liver_disease_detection.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1fAG0IphLMzJv_goOjUciNa7FQuqJ9gcm
# """

# !pip install roboflow

# from roboflow import Roboflow
# rf = Roboflow(api_key="nb0lpwpYXEsbbo5uinX3")
# project = rf.workspace("roboflow-100").project("liver-disease")
# version = project.version(2)
# dataset = version.download("yolov8")

# !pip install ultralytics
# !pip install opencv-python

from ultralytics import YOLO

# Paths to your dataset and model
data_yaml = "/content/liver-disease-2/data.yaml"  # Create this YAML file to define your dataset
model_save_path = "runs/detect/yolov11_liver_tumor"

# 1. Load the YOLOv11 model
model = YOLO("yolov8n.pt")  # Using YOLOv8 as YOLOv11 is currently based on Ultralytics core

# 2. Train the model
model.train(
    data=data_yaml,  # Path to the dataset YAML
    epochs=25,       # Number of epochs
    imgsz=640,       # Image size
    batch=16,        # Batch size
    name="liver_disease_model.pt"  # Save results under this name
)

# 3. Evaluate the model
results = model.val()

import cv2
import matplotlib.pyplot as plt
from ultralytics import YOLO
import os

def plot_ground_truth(image_path, label_path):
    """
    Plots the ground-truth bounding boxes from the label file on the given image.
    """
    # Load the image
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Read label file and draw boxes
    with open(label_path, "r") as file:
        for line in file:
            data = line.strip().split()
            cls, cx, cy, w, h = map(float, data)

            # Convert normalized coordinates (cx, cy, w, h) to pixel coordinates
            height, width, _ = img.shape
            x1 = int((cx - w / 2) * width)
            y1 = int((cy - h / 2) * height)
            x2 = int((cx + w / 2) * width)
            y2 = int((cy + h / 2) * height)

            # Draw the bounding box (green for ground-truth)
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img, "tumor (GT)", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Display the image with bounding boxes
    plt.figure(figsize=(10, 10))
    plt.imshow(img)
    plt.axis("off")
    plt.title("Ground Truth")
    plt.show()

    return img


def test_model(image_path, model_path="/content/runs/detect/liver_disease_model.pt/weights/best.pt"):
    """
    Uses the trained YOLOv8 model to predict bounding boxes on the given image.
    """
    # Load the trained model
    model = YOLO(model_path)

    # Run inference on the image
    results = model.predict(source=image_path, save=True)

    # Check if image0.jpg is created
    result_img_path = "/content/runs/detect/predict/102_1_3_61_jpg.rf.39ea4cf296518310e4501dfaf587af62.jpg"
    if not os.path.exists(result_img_path):
        print(f"Error: {result_img_path} does not exist.")
        return

    # Visualize predictions
    results_img = cv2.imread(result_img_path)
    if results_img is None:
        print(f"Error: Failed to read {result_img_path}.")
        return

    results_img = cv2.cvtColor(results_img, cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(10, 10))
    plt.imshow(results_img)
    plt.axis("off")
    plt.title("Predictions")
    plt.show()



# Paths to image and label file
image_path = "/content/liver-disease-2/test/images/102_3_4_58_jpg.rf.25b691433409fe94651c1adcce6075e0.jpg"  # Replace with the image path
label_path = "/content/liver-disease-2/test/labels/102_3_4_58_jpg.rf.25b691433409fe94651c1adcce6075e0.txt"  # Replace with the corresponding label file path

# 1. Plot Ground Truth
gt_img = plot_ground_truth(image_path, label_path)

# 2. Test the Model
test_model(image_path)

import yaml

# Specify the path to your .yaml file
file_path = "/content/liver-disease-2/data.yaml"

# Open and load the .yaml file
with open(file_path, 'r') as file:
    data = yaml.safe_load(file)

# Print the contents of the file
print(data)

import cv2
import matplotlib.pyplot as plt
from ultralytics import YOLO

def test_model(image_path, model_path="/content/runs/detect/liver_disease_model.pt/weights/best.pt"):
    """
    Enhances the YOLO model predictions by calculating tumor size, location, severity, and count.
    """
    # Load the trained model
    model = YOLO(model_path)

    # Run inference on the image
    results = model.predict(source=image_path, save=False)  # Do not save in 'runs/detect/'

    # Extract bounding boxes, labels, and confidences
    boxes = results[0].boxes.xyxy  # Bounding box coordinates
    labels = results[0].boxes.cls  # Class labels
    confidences = results[0].boxes.conf  # Confidence scores

    # Load the image
    img = cv2.imread(image_path)

    # Tumor details
    tumor_details = []

    # Loop through results and process each bounding box
    for i in range(len(boxes)):
        x1, y1, x2, y2 = map(int, boxes[i])  # Convert box coordinates to integers
        label = int(labels[i])  # Convert label to integer
        confidence = confidences[i]  # Confidence score



        # label name
        if label == 0:
          label = "ballooning"
        elif label == 1:
          label = "fibrosis"
        elif label == 2:
          label = "inflammation"
        else :
          label = "steatosis"

        # Calculate size (area) of the tumor
        width = round((x2 - x1) * 0.2645833333)
        height = round((y2 - y1) * 0.2645833333)
        area = width * height

        # Determine severity based on tumor size
        if area < 1000:
            severity = "Low"
        elif 1000 <= area < 5000:
            severity = "Moderate"
        else:
            severity = "High"

        # Determine tumor location (e.g., divide liver into quadrants)
        center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2
        if center_x < img.shape[1] // 2 and center_y < img.shape[0] // 2:
            location = "Upper Left lobe"
        elif center_x >= img.shape[1] // 2 and center_y < img.shape[0] // 2:
            location = "Upper Right lobe"
        elif center_x < img.shape[1] // 2 and center_y >= img.shape[0] // 2:
            location = "Lower Left lobe"
        else:
            location = "Lower Right lobe"

        # Append details
        tumor_details.append({
            "label": label,
            "confidence": round(float(confidence), 2),
            "area": area,
            "size": f"{width}mm x {height}mm",
            "location": location,
            "severity": severity
        })

        # Draw the bounding box
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)
        text = f"Class {label}, {severity} ({confidence:.2f})"
        cv2.putText(img, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

    # Save the image with bounding boxes as 'output1.jpg'
    output_path = "output1.jpg"
    cv2.imwrite(output_path, img)

    # Visualize predictions
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(10, 10))
    plt.imshow(img_rgb)
    plt.axis("off")
    plt.title("Predictions")
    plt.show()

    print(f"Output image saved as {output_path}")
    print("\nDisease Details:")
    for i, tumor in enumerate(tumor_details, 1):
        print(f"Disease {i}: {tumor}")

# Example usage
image_path = "/content/liver-disease-2/test/images/15_242_212_21_14_jpg.rf.bb198ea5702fcacb085154f269f51906.jpg"  # Replace with your image path

# Test the model and save the result as output1.jpg
test_model(image_path)

